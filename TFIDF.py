import DataReader as DR
from sklearn import svm
from nltk.tokenize import word_tokenize,RegexpTokenizer
from nltk.stem import *
import re
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.linear_model import LogisticRegression as LR
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier as NN
#from sklearn.metrics import confusion_matrix
#from pandas_ml import ConfusionMatrix
from sklearn.decomposition import  LatentDirichletAllocation

#import seaborn as sns

#Read training data
Ang_Songs=DR.readData("Data-Set/Angry/Train/","angry")
Hap_Songs=DR.readData("Data-Set/Happy/Train/","happy")
Sad_Songs=DR.readData("Data-Set/Sad/Train/","sad")
#Rel_Songs=DR.readData("Data-Set/Relaxed/Train/","relaxed")
##SongsTrain=[Ang_Songs,Hap_Songs,Sad_Songs,Rel_Songs]
SongsTrain=[Ang_Songs,Hap_Songs,Sad_Songs]

#ReadTestingData
AngT_Songs=DR.readData("Data-Set/Angry/Test/","angry")
HapT_Songs=DR.readData("Data-Set/Happy/Test/","happy")
SadT_Songs=DR.readData("Data-Set/Sad/Test/","sad")
#RelT_Songs=DR.readData("Data-Set/Relaxed/Test/","relaxed")

SongsTTrain=[AngT_Songs,HapT_Songs,SadT_Songs]
##SongsTTrain=[AngT_Songs,HapT_Songs,SadT_Songs,RelT_Songs]

SongsWordsTrain=[[],[]]
for i in range(3):
##for i in range(4):
	for song in SongsTrain[i]:
        ##s=song[3]
		s=song[4]
		SongsWordsTrain[0].append(s)
		SongsWordsTrain[1].append(i)

SongsWordsTTrain=[[],[]]
for i in range(3):
##for i in range(4):
	for song in SongsTTrain[i]:
        ##s=song[3]
		s=song[4]
		SongsWordsTTrain[0].append(s)
		SongsWordsTTrain[1].append(i)
     

#stemmer = PorterStemmer()
stemmer = SnowballStemmer("english")
tokenizer = RegexpTokenizer("[\wâ€™]+", flags=re.UNICODE)



def tokenize(text):
    #tokens = word_tokenize(text)
    tokens = tokenizer.tokenize(text)
    stems = []
    for item in tokens:
        stems.append(stemmer.stem(item))
    return stems
    
#print(SongWordsTrain)
#print(SongsTrain[:][3])

vectorizer = TfidfVectorizer(tokenizer=tokenize,min_df=2, ngram_range = (1,3), sublinear_tf = True, stop_words = "english")

print ("Vectorizing training...")
train_x = vectorizer.fit_transform(SongsWordsTrain[0])
print(train_x.shape)
print(train_x.getnnz())
print ("Vectorizing test...")
# print("\nThese are the feature names\n")
# print(vectorizer.get_feature_names())

test_x = vectorizer.transform(SongsWordsTTrain[0])
#print(test_x)
print ("Training...")
print ("\nNB...")
modelA = MultinomialNB()
modelA.fit(train_x, SongsWordsTrain[1])
#score on training set
print(modelA.score(train_x, SongsWordsTrain[1])) 

print(modelA.score(test_x,SongsWordsTTrain[1]))
print("NB Prediction:")
print(modelA.predict(test_x))


print ("\nSVM...")
modelB = svm.SVC(kernel='linear', C=1, gamma=1) 
modelB.fit( train_x, SongsWordsTrain[1])
#score on training set
print(modelB.score(train_x, SongsWordsTrain[1]))
#score on testing set
print(modelB.score(test_x,SongsWordsTTrain[1]))

print("SVM Prediction:")
print(modelB.predict(test_x))
"""
print ("LR...")
modelC = LR(multi_class='multinomial',solver='newton-cg')
modelC.fit( train_x, SongsWordsTrain[1])
modelC.fit( train_x, SongsWordsTrain[1])
#score on training set
print(modelC.score(train_x, SongsWordsTrain[1]))
#print(modelC.predict(test_x))

#score on testing set
print(modelC.score(test_x,SongsWordsTTrain[1]))
"""
print ("\nLR...")
modelC = LR(multi_class='multinomial',solver='newton-cg')
modelC.fit( train_x, SongsWordsTrain[1])
#score on training set
print(modelC.score(train_x, SongsWordsTrain[1]))
# print("\n\nPrediction\n")
##print(modelC.predict(test_x))

#score on test set
print(modelC.score(test_x,SongsWordsTTrain[1]))

print("LR Prediction:")
print(modelC.predict(test_x))

print ("\nKNN...")
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(train_x,SongsWordsTrain[1])
#score on training set
print(knn.score(train_x, SongsWordsTrain[1]))

#score on test set
print(knn.score(test_x,SongsWordsTTrain[1]))

print("KNN Prediction:")
print(knn.predict(test_x))


# train_x = vectorizer.fit_transform(SongsWordsTrain[0])
# #print(train_x)
# print(train_x.shape)

# print(train_x.getnnz())
# print ("Vectorizing test...")
# #print(vectorizer.get_feature_names())

# test_x = vectorizer.transform(SongsWordsTTrain[0])
# #print(test_x)


# print ("Training...")

# print ("NB...")
# modelA = MultinomialNB()
# modelA.fit(train_x, SongsWordsTrain[1])
# #score on training set
# print(modelA.score(train_x, SongsWordsTrain[1]))

# print(modelA.score(test_x,SongsWordsTTrain[1]))
# predict=modelA.predict(test_x)

# #confusion_matrix = ConfusionMatrix(SongsWordsTTrain[1], predict)
# #sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,xticklabels=SongsWordsTrain[1], yticklabels=SongsWordsTTrain[1])
# #print(confusion_matrix)
# """confusion_matrix.plot()
# confusion_matrix.print_stats()
# plt.show()
# """

# print ("SVM...")
# modelB = svm.SVC(kernel='linear', C=1, gamma=1) 
# modelB.fit( train_x, SongsWordsTrain[1])
# #score on training set
# print(modelB.score(train_x, SongsWordsTrain[1]))
# #print(modelB.predict(test_x))

# #score on test set
# print(modelB.score(test_x,SongsWordsTTrain[1]))

# print ("LR...")
# modelC = LR(multi_class='multinomial',solver='newton-cg')
# modelC.fit( train_x, SongsWordsTrain[1])
# #score on training set
# print(modelC.score(train_x, SongsWordsTrain[1]))
# #print(modelC.predict(test_x))

# #score on test set
# print(modelC.score(test_x,SongsWordsTTrain[1]))

# print ("KNN...")
# knn = KNeighborsClassifier()
# knn.fit(train_x,SongsWordsTrain[1])
# #score on training set
# print(knn.score(train_x, SongsWordsTrain[1]))

# #score on test set
# print(knn.score(test_x,SongsWordsTTrain[1]))


# """
# lda = LatentDirichletAllocation(n_components=10, max_iter=5,
#                                 learning_method='online',
#                                 learning_offset=50.,
#                                 random_state=0)
# lda.fit(train_x,SongsWordsTrain[0])
# print(lda.score(train_x, SongsWordsTrain[1]))
# print(lda.score(test_x,SongsWordsTTrain[1]))

# """

# """
# print("RandomForestClassifier..")
# clf = RandomForestClassifier(max_depth=2)
# clf.fit(train_x,SongsWordsTrain[1])
# #score on training set
# print(clf.score(train_x, SongsWordsTrain[1]))
# #score on test set
# print(clf.score(test_x,SongsWordsTTrain[1]))

# print("MLPClassifier..")
# neuralnet=NN(solver='lbfgs',activation='logistic')
# neuralnet.fit(train_x,SongsWordsTrain[1])
# #score on training set
# print(neuralnet.score(train_x, SongsWordsTrain[1]))

# #score on test set
# print(neuralnet.score(test_x,SongsWordsTTrain[1]))
# """


